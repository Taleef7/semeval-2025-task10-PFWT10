{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Subtask 1 Annotations and Verify a Raw Document</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Annotations:\n",
      "          article_id entity_mention  start_offset  end_offset    main_role  \\\n",
      "0  EN_UA_103861.txt        Chinese           791         797   Antagonist   \n",
      "1  EN_UA_103861.txt          China          1516        1520   Antagonist   \n",
      "2  EN_UA_103861.txt          Hamas          2121        2125   Antagonist   \n",
      "3  EN_UA_103861.txt   Donald Trump          4909        4920  Protagonist   \n",
      "4  EN_UA_021270.txt         Yermak           667         672   Antagonist   \n",
      "\n",
      "       fine_grained_roles  \n",
      "0                   [Spy]  \n",
      "1            [Instigator]  \n",
      "2             [Terrorist]  \n",
      "3  [Peacemaker, Guardian]  \n",
      "4           [Incompetent]  \n",
      "\n",
      "Sample Article Content (EN_UA_103861.txt):\n",
      " The World Needs Peacemaker Trump Again \n",
      "\n",
      " by Jeff Crouere, The Liberty Daily:\n",
      "\n",
      "The world is in total chaos after 39 months of the Biden presidency. The southern border of our country is porous and millions of individuals from around the world have descended on our country.\n",
      "\n",
      "These “undocumented migrants” include terrorists, drug dealers, and intelligence agents of countries such as our enemy, China. It should alarm every American that 22,233 Chinese nationals have illegally entered the United Sta\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths to English data (adjust paths if needed)\n",
    "en_annotations_path = \"EN/annotations/subtask-1-annotations.txt\"\n",
    "en_raw_docs_path = \"EN/raw-documents/\"\n",
    "\n",
    "# Custom parser function to handle multiple fine-grained roles\n",
    "def parse_annotations(line):\n",
    "    parts = line.strip().split(\"\\t\")  # Split by tab\n",
    "    article_id, entity_mention, start_offset, end_offset, main_role = parts[:5]\n",
    "    fine_grained_roles = parts[5:]  # Capture remaining parts as fine-grained roles\n",
    "    return {\n",
    "        \"article_id\": article_id,\n",
    "        \"entity_mention\": entity_mention,\n",
    "        \"start_offset\": int(start_offset),\n",
    "        \"end_offset\": int(end_offset),\n",
    "        \"main_role\": main_role,\n",
    "        \"fine_grained_roles\": fine_grained_roles,\n",
    "    }\n",
    "\n",
    "# Read the annotation file line-by-line\n",
    "with open(en_annotations_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [parse_annotations(line) for line in f]\n",
    "\n",
    "# Convert to DataFrame\n",
    "annotations = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"Sample Annotations:\\n\", annotations.head())\n",
    "\n",
    "# Pick the first article's ID from annotations to verify\n",
    "sample_article_id = annotations.iloc[0][\"article_id\"]\n",
    "article_file_path = os.path.join(en_raw_docs_path, f\"{sample_article_id}\")\n",
    "\n",
    "# Load and print a snippet of the raw document\n",
    "with open(article_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    article_content = f.read()\n",
    "\n",
    "print(f\"\\nSample Article Content ({sample_article_id}):\\n\", article_content[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Annotations:\n",
      "          article_id entity_mention  start_offset  end_offset    main_role  \\\n",
      "0  EN_UA_103861.txt        Chinese           791         797   Antagonist   \n",
      "1  EN_UA_103861.txt          China          1516        1520   Antagonist   \n",
      "2  EN_UA_103861.txt          Hamas          2121        2125   Antagonist   \n",
      "3  EN_UA_103861.txt   Donald Trump          4909        4920  Protagonist   \n",
      "4  EN_UA_021270.txt         Yermak           667         672   Antagonist   \n",
      "\n",
      "       fine_grained_roles  \n",
      "0                   [Spy]  \n",
      "1            [Instigator]  \n",
      "2             [Terrorist]  \n",
      "3  [Peacemaker, Guardian]  \n",
      "4           [Incompetent]  \n",
      "\n",
      "Sample Article Content (EN_UA_103861.txt):\n",
      " The World Needs Peacemaker Trump Again \n",
      "\n",
      " by Jeff Crouere, The Liberty Daily:\n",
      "\n",
      "The world is in total chaos after 39 months of the Biden presidency. The southern border of our country is porous and millions of individuals from around the world have descended on our country.\n",
      "\n",
      "These “undocumented migrants” include terrorists, drug dealers, and intelligence agents of countries such as our enemy, China. It should alarm every American that 22,233 Chinese nationals have illegally entered the United Sta\n",
      "Sample Encodings: tensor([[     0, 118255,      7,      2,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1],\n",
      "        [     0,  62774,      2,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1]])\n",
      "Sample Main Labels: tensor([0, 0])\n",
      "Sample Fine-Grained Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths to English data (adjust paths if needed)\n",
    "en_annotations_path = \"EN/annotations/subtask-1-annotations.txt\"\n",
    "en_raw_docs_path = \"EN/raw-documents/\"\n",
    "\n",
    "# Custom parser function to handle multiple fine-grained roles\n",
    "def parse_annotations(line):\n",
    "    parts = line.strip().split(\"\\t\")  # Split by tab\n",
    "    article_id, entity_mention, start_offset, end_offset, main_role = parts[:5]\n",
    "    fine_grained_roles = parts[5:]  # Capture remaining parts as fine-grained roles\n",
    "    return {\n",
    "        \"article_id\": article_id,\n",
    "        \"entity_mention\": entity_mention,\n",
    "        \"start_offset\": int(start_offset),\n",
    "        \"end_offset\": int(end_offset),\n",
    "        \"main_role\": main_role,\n",
    "        \"fine_grained_roles\": fine_grained_roles,\n",
    "    }\n",
    "\n",
    "# Read the annotation file line-by-line\n",
    "with open(en_annotations_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [parse_annotations(line) for line in f]\n",
    "\n",
    "# Convert to DataFrame\n",
    "annotations = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"Sample Annotations:\\n\", annotations.head())\n",
    "\n",
    "# Pick the first article's ID from annotations to verify\n",
    "sample_article_id = annotations.iloc[0][\"article_id\"]\n",
    "article_file_path = os.path.join(en_raw_docs_path, f\"{sample_article_id}\")\n",
    "\n",
    "# Load and print a snippet of the raw document\n",
    "with open(article_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    article_content = f.read()\n",
    "\n",
    "print(f\"\\nSample Article Content ({sample_article_id}):\\n\", article_content[:500])\n",
    "\n",
    "\n",
    "# Initialize the XLM-RoBERTa tokenizer\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# Function to extract text from articles based on offsets\n",
    "def extract_text(article_id, start_offset, end_offset):\n",
    "    with open(f\"EN/raw-documents/{article_id}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    return content[start_offset:end_offset]\n",
    "\n",
    "# Add extracted text to the DataFrame\n",
    "annotations[\"extracted_text\"] = annotations.apply(\n",
    "    lambda row: extract_text(row[\"article_id\"], row[\"start_offset\"], row[\"end_offset\"]), axis=1\n",
    ")\n",
    "\n",
    "# Tokenize the extracted text\n",
    "encodings = tokenizer(\n",
    "    list(annotations[\"extracted_text\"]),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Encode labels for main roles (e.g., Protagonist, Antagonist) into numerical values\n",
    "main_role_encoder = {role: i for i, role in enumerate(annotations[\"main_role\"].unique())}\n",
    "annotations[\"main_role_encoded\"] = annotations[\"main_role\"].map(main_role_encoder)\n",
    "\n",
    "# Encode fine-grained roles into multi-label vectors\n",
    "fine_grained_roles = list(set([role for roles in annotations[\"fine_grained_roles\"] for role in roles]))\n",
    "fine_role_encoder = {role: i for i, role in enumerate(fine_grained_roles)}\n",
    "\n",
    "def encode_fine_grained_roles(roles):\n",
    "    encoding = [0] * len(fine_role_encoder)\n",
    "    for role in roles:\n",
    "        encoding[fine_role_encoder[role]] = 1\n",
    "    return encoding\n",
    "\n",
    "annotations[\"fine_grained_encoded\"] = annotations[\"fine_grained_roles\"].apply(encode_fine_grained_roles)\n",
    "\n",
    "# Convert encoded labels into tensors\n",
    "main_labels_tensor = torch.tensor(list(annotations[\"main_role_encoded\"]), dtype=torch.long)\n",
    "fine_labels_tensor = torch.tensor(list(annotations[\"fine_grained_encoded\"]), dtype=torch.float32)\n",
    "\n",
    "print(\"Sample Encodings:\", encodings[\"input_ids\"][:2])\n",
    "print(\"Sample Main Labels:\", main_labels_tensor[:2])\n",
    "print(\"Sample Fine-Grained Labels:\", fine_labels_tensor[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train/Validation Split and DataLoader Setup</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 331\n",
      "Number of validation samples: 83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Split the data into 80% train and 20% validation\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(annotations)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Prepare train and validation tensors\n",
    "train_encodings = {key: val[train_indices] for key, val in encodings.items()}\n",
    "val_encodings = {key: val[val_indices] for key, val in encodings.items()}\n",
    "\n",
    "train_main_labels = main_labels_tensor[train_indices]\n",
    "train_fine_labels = fine_labels_tensor[train_indices]\n",
    "\n",
    "val_main_labels = main_labels_tensor[val_indices]\n",
    "val_fine_labels = fine_labels_tensor[val_indices]\n",
    "\n",
    "# Create TensorDataset and DataLoader objects\n",
    "train_dataset = TensorDataset(\n",
    "    train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"],\n",
    "    train_main_labels, train_fine_labels\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    val_encodings[\"input_ids\"], val_encodings[\"attention_mask\"],\n",
    "    val_main_labels, val_fine_labels\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Set Up the Model and Trainer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input IDs: torch.Size([14])\n",
      "Sample Labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.]) torch.Size([23])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input IDs: torch.Size([14])\n",
      "Sample Labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.]) torch.Size([23])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe8b32c4ece400fadbf4f601ea8ebea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6451, 'grad_norm': 10.242195129394531, 'learning_rate': 4.2647058823529415e-05, 'epoch': 0.29}\n",
      "{'loss': 0.485, 'grad_norm': 2.5487565994262695, 'learning_rate': 3.529411764705883e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3567, 'grad_norm': 1.210931658744812, 'learning_rate': 2.7941176470588236e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fdc6d9f5434d7eac88087c61a5c03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         5\n",
      "           1       1.00      0.00      0.00         5\n",
      "           2       1.00      0.00      0.00         4\n",
      "           3       1.00      0.00      0.00         2\n",
      "           4       1.00      0.00      0.00         1\n",
      "           5       1.00      0.00      0.00         1\n",
      "           6       1.00      0.00      0.00         5\n",
      "           7       1.00      1.00      1.00         0\n",
      "           8       1.00      0.00      0.00        11\n",
      "           9       1.00      1.00      1.00         0\n",
      "          10       1.00      0.00      0.00         6\n",
      "          11       1.00      0.00      0.00        10\n",
      "          12       1.00      0.00      0.00         1\n",
      "          13       1.00      0.00      0.00         1\n",
      "          14       1.00      0.00      0.00         5\n",
      "          15       1.00      0.00      0.00         6\n",
      "          16       1.00      0.00      0.00         2\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       1.00      0.00      0.00         5\n",
      "          19       1.00      0.00      0.00        10\n",
      "          20       1.00      0.00      0.00         2\n",
      "          21       1.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       1.00      0.00      0.00        85\n",
      "   macro avg       1.00      0.09      0.09        85\n",
      "weighted avg       1.00      0.00      0.00        85\n",
      " samples avg       1.00      0.00      0.00        85\n",
      "\n",
      "{'eval_loss': 0.2747412621974945, 'eval_main_accuracy': 0.6746987951807228, 'eval_fine_f1_score': 0.0, 'eval_exact_match_main': 0.6746987951807228, 'eval_exact_match_fine': 0.0, 'eval_runtime': 7.0759, 'eval_samples_per_second': 11.73, 'eval_steps_per_second': 1.272, 'epoch': 1.0}\n",
      "{'loss': 0.3004, 'grad_norm': 0.6339452266693115, 'learning_rate': 2.058823529411765e-05, 'epoch': 1.18}\n",
      "{'loss': 0.2694, 'grad_norm': 0.522925615310669, 'learning_rate': 1.323529411764706e-05, 'epoch': 1.47}\n",
      "{'loss': 0.2573, 'grad_norm': 0.5798428654670715, 'learning_rate': 5.882352941176471e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b8d55c8d644bb681dc1159b899b2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         5\n",
      "           1       1.00      0.00      0.00         5\n",
      "           2       1.00      0.00      0.00         4\n",
      "           3       1.00      0.00      0.00         2\n",
      "           4       1.00      0.00      0.00         1\n",
      "           5       1.00      0.00      0.00         1\n",
      "           6       1.00      0.00      0.00         5\n",
      "           7       1.00      1.00      1.00         0\n",
      "           8       1.00      0.00      0.00        11\n",
      "           9       1.00      1.00      1.00         0\n",
      "          10       1.00      0.00      0.00         6\n",
      "          11       1.00      0.00      0.00        10\n",
      "          12       1.00      0.00      0.00         1\n",
      "          13       1.00      0.00      0.00         1\n",
      "          14       1.00      0.00      0.00         5\n",
      "          15       1.00      0.00      0.00         6\n",
      "          16       1.00      0.00      0.00         2\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       1.00      0.00      0.00         5\n",
      "          19       1.00      0.00      0.00        10\n",
      "          20       1.00      0.00      0.00         2\n",
      "          21       1.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       1.00      0.00      0.00        85\n",
      "   macro avg       1.00      0.09      0.09        85\n",
      "weighted avg       1.00      0.00      0.00        85\n",
      " samples avg       1.00      0.00      0.00        85\n",
      "\n",
      "{'eval_loss': 0.2541513442993164, 'eval_main_accuracy': 0.6746987951807228, 'eval_fine_f1_score': 0.0, 'eval_exact_match_main': 0.6746987951807228, 'eval_exact_match_fine': 0.0, 'eval_runtime': 4.8337, 'eval_samples_per_second': 17.171, 'eval_steps_per_second': 1.862, 'epoch': 2.0}\n",
      "{'train_runtime': 600.9716, 'train_samples_per_second': 1.102, 'train_steps_per_second': 0.113, 'train_loss': 0.3706405934165506, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=68, training_loss=0.3706405934165506, metrics={'train_runtime': 600.9716, 'train_samples_per_second': 1.102, 'train_steps_per_second': 0.113, 'total_flos': 4763619226632.0, 'train_loss': 0.3706405934165506, 'epoch': 2.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you've already run preprocessing and tokenization\n",
    "\n",
    "# Step 1: Initialize the Dataset Class\n",
    "class EntityFramingDataset(Dataset):\n",
    "    def __init__(self, encodings, main_labels, fine_labels):\n",
    "        self.encodings = encodings\n",
    "        self.main_labels = main_labels\n",
    "        self.fine_labels = fine_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.main_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Combine main role and fine-grained roles into one label tensor\n",
    "        labels = torch.cat([self.main_labels[idx].unsqueeze(0), self.fine_labels[idx]], dim=0)\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = labels\n",
    "        return item\n",
    "\n",
    "# Step 2: Prepare the Train and Validation Data\n",
    "train_dataset = EntityFramingDataset(train_encodings, train_main_labels, train_fine_labels)\n",
    "val_dataset = EntityFramingDataset(val_encodings, val_main_labels, val_fine_labels)\n",
    "\n",
    "# Step 3: Verify the Dataset Shapes (Optional Debugging Step)\n",
    "sample = train_dataset[0]\n",
    "print(\"Sample Input IDs:\", sample[\"input_ids\"].shape)\n",
    "print(\"Sample Labels:\", sample[\"labels\"], sample[\"labels\"].shape)\n",
    "\n",
    "# Step 4: Initialize the Model\n",
    "# Adjust the number of labels to match the total number of roles\n",
    "num_main_labels = 1  # Assuming a single main role prediction\n",
    "num_fine_labels = len(fine_role_encoder)  # Number of fine-grained roles\n",
    "total_labels = num_main_labels + num_fine_labels  # Total number of labels\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    num_labels=total_labels,  # Total labels for the classification task\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "def exact_match_ratio(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the exact match ratio for multi-label predictions.\n",
    "    Handles both 1D and 2D cases gracefully.\n",
    "    \"\"\"\n",
    "    # Convert tensors to NumPy arrays if needed\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "    # For single-label case\n",
    "    if y_true.ndim == 1:\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "    # For multi-label case (2D)\n",
    "    elif y_true.ndim == 2:\n",
    "        return np.mean(np.all(y_true == y_pred, axis=1))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected dimensions in labels.\")\n",
    "\n",
    "\n",
    "# Step 5: Define the Metric Function for Evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Ensure logits and labels are tensors\n",
    "    logits_tensor = torch.tensor(logits)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    # Convert logits to binary predictions\n",
    "    main_pred = (logits_tensor[:, 0] > 0).int()\n",
    "    fine_pred = (torch.sigmoid(logits_tensor[:, 1:]) > 0.5).int()\n",
    "\n",
    "    # Extract labels\n",
    "    main_labels = labels_tensor[:, 0].int()\n",
    "    fine_labels = (labels_tensor[:, 1:] > 0).int()  # Ensure binary format\n",
    "\n",
    "    # Calculate metrics\n",
    "    main_acc = accuracy_score(main_labels.cpu(), main_pred.cpu())\n",
    "    fine_f1 = f1_score(fine_labels.cpu(), fine_pred.cpu(), average=\"micro\", zero_division=1)\n",
    "    exact_match_main = exact_match_ratio(main_labels.cpu(), main_pred.cpu())\n",
    "    exact_match_fine = exact_match_ratio(fine_labels.cpu(), fine_pred.cpu())\n",
    "\n",
    "    # Optional: Print detailed classification report for debugging\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(fine_labels.cpu(), fine_pred.cpu(), zero_division=1))\n",
    "\n",
    "    return {\n",
    "        \"main_accuracy\": main_acc,\n",
    "        \"fine_f1_score\": fine_f1,\n",
    "        \"exact_match_main\": exact_match_main,\n",
    "        \"exact_match_fine\": exact_match_fine,\n",
    "    }\n",
    "\n",
    "\n",
    "sample = train_dataset[0]\n",
    "print(\"Sample Input IDs:\", sample[\"input_ids\"].shape)\n",
    "print(\"Sample Labels:\", sample[\"labels\"], sample[\"labels\"].shape)\n",
    "\n",
    "\n",
    "# Step 6: Set Up the Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",        # Directory to save checkpoints\n",
    "    evaluation_strategy=\"epoch\",   # Evaluate at the end of each epoch\n",
    "    logging_dir=\"./logs\",          # Directory for logs\n",
    "    logging_steps=10,              # Log every 10 steps\n",
    "    per_device_train_batch_size=10, # Batch size for training\n",
    "    per_device_eval_batch_size=10,  # Batch size for evaluation\n",
    "    num_train_epochs=2,            # Number of epochs\n",
    "    save_strategy=\"epoch\",         # Save model at the end of each epoch\n",
    "    load_best_model_at_end=True,   # Load the best model after training\n",
    "    metric_for_best_model=\"fine_f1_score\",  # Select the best model based on F1 score\n",
    "    greater_is_better=True,        # Higher F1 score is better\n",
    ")\n",
    "\n",
    "# Step 7: Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics  # Attach custom metric function\n",
    ")\n",
    "\n",
    "# Step 8: Start Training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7679cc1e298c48868eaf43da9f846d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         5\n",
      "           1       1.00      0.00      0.00         5\n",
      "           2       1.00      0.00      0.00         4\n",
      "           3       1.00      0.00      0.00         2\n",
      "           4       1.00      0.00      0.00         1\n",
      "           5       1.00      0.00      0.00         1\n",
      "           6       1.00      0.00      0.00         5\n",
      "           7       1.00      1.00      1.00         0\n",
      "           8       1.00      0.00      0.00        11\n",
      "           9       1.00      1.00      1.00         0\n",
      "          10       1.00      0.00      0.00         6\n",
      "          11       1.00      0.00      0.00        10\n",
      "          12       1.00      0.00      0.00         1\n",
      "          13       1.00      0.00      0.00         1\n",
      "          14       1.00      0.00      0.00         5\n",
      "          15       1.00      0.00      0.00         6\n",
      "          16       1.00      0.00      0.00         2\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       1.00      0.00      0.00         5\n",
      "          19       1.00      0.00      0.00        10\n",
      "          20       1.00      0.00      0.00         2\n",
      "          21       1.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       1.00      0.00      0.00        85\n",
      "   macro avg       1.00      0.09      0.09        85\n",
      "weighted avg       1.00      0.00      0.00        85\n",
      " samples avg       1.00      0.00      0.00        85\n",
      "\n",
      "Evaluation Results: {'eval_loss': 0.2747412621974945, 'eval_main_accuracy': 0.6746987951807228, 'eval_fine_f1_score': 0.0, 'eval_exact_match_main': 0.6746987951807228, 'eval_exact_match_fine': 0.0, 'eval_runtime': 6.743, 'eval_samples_per_second': 12.309, 'eval_steps_per_second': 1.335, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the validation dataset\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Evaluation Results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./entity-framing-model2\")\n",
    "tokenizer.save_pretrained(\"./entity-framing-model\")\n",
    "print(\"Model and tokenizer saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Model (optional)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "loaded_model = XLMRobertaForSequenceClassification.from_pretrained(\"./entity-framing-model2\")\n",
    "loaded_tokenizer = XLMRobertaTokenizer.from_pretrained(\"./entity-framing-model\")\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9077cec5434079b9f0cc2622b6328c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         5\n",
      "           1       1.00      0.00      0.00         5\n",
      "           2       1.00      0.00      0.00         4\n",
      "           3       1.00      0.00      0.00         2\n",
      "           4       1.00      0.00      0.00         1\n",
      "           5       1.00      0.00      0.00         1\n",
      "           6       1.00      0.00      0.00         5\n",
      "           7       1.00      1.00      1.00         0\n",
      "           8       1.00      0.00      0.00        11\n",
      "           9       1.00      1.00      1.00         0\n",
      "          10       1.00      0.00      0.00         6\n",
      "          11       1.00      0.00      0.00        10\n",
      "          12       1.00      0.00      0.00         1\n",
      "          13       1.00      0.00      0.00         1\n",
      "          14       1.00      0.00      0.00         5\n",
      "          15       1.00      0.00      0.00         6\n",
      "          16       1.00      0.00      0.00         2\n",
      "          17       1.00      0.00      0.00         1\n",
      "          18       1.00      0.00      0.00         5\n",
      "          19       1.00      0.00      0.00        10\n",
      "          20       1.00      0.00      0.00         2\n",
      "          21       1.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       1.00      0.00      0.00        85\n",
      "   macro avg       1.00      0.09      0.09        85\n",
      "weighted avg       1.00      0.00      0.00        85\n",
      " samples avg       1.00      0.00      0.00        85\n",
      "\n",
      "Updated Evaluation Results: {'eval_loss': 0.2747412621974945, 'eval_main_accuracy': 0.6746987951807228, 'eval_fine_f1_score': 0.0, 'eval_exact_match_main': 0.6746987951807228, 'eval_exact_match_fine': 0.0, 'eval_runtime': 7.1549, 'eval_samples_per_second': 11.6, 'eval_steps_per_second': 1.258, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Re-run evaluation\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Updated Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predictions on new data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = loaded_model(**inputs)\n",
    "    logits = outputs.logits.detach().numpy()\n",
    "\n",
    "    # Convert logits to binary predictions\n",
    "    predictions = (logits > 0).astype(int)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "example_text = \"Donald Trump visited China to promote peace.\"\n",
    "predictions = predict(example_text)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd14d8762625481894972b138f791dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Role Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.81        56\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.67        83\n",
      "   macro avg       0.22      0.33      0.27        83\n",
      "weighted avg       0.46      0.67      0.54        83\n",
      "\n",
      "Fine-Grained Role Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00        11\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.00      0.00      0.00         6\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       0.00      0.00      0.00        10\n",
      "          20       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.00      0.00      0.00        85\n",
      "   macro avg       0.00      0.00      0.00        85\n",
      "weighted avg       0.00      0.00      0.00        85\n",
      " samples avg       0.00      0.00      0.00        85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\talee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions and true labels from the validation set\n",
    "preds_output = trainer.predict(val_dataset)\n",
    "preds = (preds_output.predictions > 0).astype(int)\n",
    "\n",
    "# Create a classification report\n",
    "print(\"Main Role Classification Report:\\n\", classification_report(val_main_labels, preds[:, 0]))\n",
    "print(\"Fine-Grained Role Classification Report:\\n\", classification_report(val_fine_labels, preds[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Grained Role Distribution:\n",
      " fine_grained_roles\n",
      "Instigator           49\n",
      "Guardian             40\n",
      "Conspirator          38\n",
      "Incompetent          35\n",
      "Foreign Adversary    35\n",
      "Victim               33\n",
      "Tyrant               29\n",
      "Deceiver             26\n",
      "Saboteur             20\n",
      "Virtuous             19\n",
      "Corrupt              17\n",
      "Peacemaker           15\n",
      "Terrorist            14\n",
      "Underdog             12\n",
      "Rebel                11\n",
      "Martyr               11\n",
      "Bigot                 9\n",
      "Traitor               8\n",
      "Scapegoat             8\n",
      "Exploited             6\n",
      "Spy                   3\n",
      "Forgotten             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of fine-grained roles and count occurrences\n",
    "fine_role_counts = annotations[\"fine_grained_roles\"].explode().value_counts()\n",
    "print(\"Fine-Grained Role Distribution:\\n\", fine_role_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
