{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xRBUsjHX17dk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers import BertTokenizer, BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LHcWvFsLEqVP"
   },
   "outputs": [],
   "source": [
    "def load_annotations_with_taxonomy(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) >= 3:\n",
    "                article_id = fields[0]\n",
    "                taxonomy_narratives = fields[1].split(';')\n",
    "                sub_narratives_full = fields[2].split(';')\n",
    "\n",
    "                # Extract taxonomy from the first narrative prefix (e.g., \"URW\", \"CC\", or \"Other\")\n",
    "                taxonomy = taxonomy_narratives[0].split(':')[0].strip()\n",
    "\n",
    "                # Extract narratives and sub-narratives, removing taxonomy prefix\n",
    "                narratives = [n.split(':', 1)[1].strip() if ':' in n else n for n in taxonomy_narratives]\n",
    "                sub_narratives = [s.split(':', 1)[1].strip() if ':' in s else s for s in sub_narratives_full]\n",
    "\n",
    "                data.append([article_id, taxonomy, narratives, sub_narratives])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"article_id\", \"taxonomy\", \"narratives\", \"sub_narratives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eR11J_QQEyMe"
   },
   "outputs": [],
   "source": [
    "def load_all_articles(raw_documents_folder):\n",
    "    articles = {}\n",
    "    for filename in os.listdir(raw_documents_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            article_id = filename.split('.')[0]\n",
    "            with open(os.path.join(raw_documents_folder, filename), 'r', encoding='utf-8') as f:\n",
    "                articles[article_id] = f.read()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yi4gc_UyE2zI"
   },
   "outputs": [],
   "source": [
    "annotations = load_annotations_with_taxonomy('./EN/subtask-2-annotations.txt')\n",
    "articles = load_all_articles('./EN/raw-documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = load_annotations_with_taxonomy('./HI/subtask-2-annotations.txt')\n",
    "# articles = load_all_articles('./HI/raw-documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = load_annotations_with_taxonomy('./PT/subtask-2-annotations.txt')\n",
    "# articles = load_all_articles('./PT/raw-documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = load_annotations_with_taxonomy('./BG/subtask-2-annotations.txt')\n",
    "# articles = load_all_articles('./BG/raw-documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = load_annotations_with_taxonomy('./RU/subtask-2-annotations.txt')\n",
    "# articles = load_all_articles('./RU/raw-documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        # Tokenize and create input tensors\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        # Get model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        \n",
    "        # Extract [CLS] token embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(cls_embedding)\n",
    "    \n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gabtg_VRXQUI",
    "outputId": "f6a2cbc8-13c5-4cac-e401-effa365c9a3a"
   },
   "outputs": [],
   "source": [
    "# Prepare the taxonomy data and load corresponding text content\n",
    "taxonomy_encoder = LabelEncoder()\n",
    "annotations['taxonomy_encoded'] = taxonomy_encoder.fit_transform(annotations['taxonomy'])\n",
    "\n",
    "taxon = []\n",
    "taxonomies = annotations['taxonomy_encoded'].tolist()\n",
    "for article_id in annotations['article_id']:\n",
    "    text = articles.get(article_id.split('.')[0], \"\")\n",
    "    taxon.append(text)\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(taxon, taxonomies, test_size=0.5, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization of the text data\n",
    "embedding = TfidfVectorizer(max_features=700, ngram_range=(1, 5), min_df=5, max_df=0.8, sublinear_tf=False)\n",
    "# X_train_embed = get_bert_embeddings(X_train)\n",
    "# X_test_embed = get_bert_embeddings(X_test)\n",
    "# X_train_embed = embedding.fit_transform(X_train)\n",
    "# X_test_embed = embedding.transform(X_test)\n",
    "X_train_tfidf = embedding.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = embedding.transform(X_test).toarray()\n",
    "X_train_bert = get_bert_embeddings(X_train)\n",
    "X_test_bert = get_bert_embeddings(X_test)\n",
    "X_train_tfidf = normalize(X_train_tfidf, axis=1)\n",
    "X_test_tfidf = normalize(X_test_tfidf, axis=1)\n",
    "X_train_bert = normalize(X_train_bert, axis=1)\n",
    "X_test_bert = normalize(X_test_bert, axis=1)\n",
    "X_train_embed = np.hstack((X_train_tfidf, X_train_bert))\n",
    "X_test_embed = np.hstack((X_test_tfidf, X_test_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.5%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.79      0.84      0.82        50\n",
      "       Other       0.71      0.67      0.69        87\n",
      "         URW       0.72      0.75      0.73        63\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.74      0.75      0.75       200\n",
      "weighted avg       0.73      0.73      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=6, n_estimators=100, learning_rate=0.72, subsample=0.8, colsample_bytree=0.4, objective='multi:softmax', num_class=3)\n",
    "#model = LogisticRegression(max_iter=1603, solver = 'lbfgs', penalty='l2', C=3)\n",
    "#model = SVC(kernel='linear', degree=5, C=2, probability=False)\n",
    "#model = MultinomialNB() #(0 Precision For CC)\n",
    "#model = RandomForestClassifier(n_estimators=200, max_depth=6, min_samples_split=5, min_samples_leaf=10, random_state=42)\n",
    "\n",
    "model.fit(X_train_embed, y_train)\n",
    "y_pred = model.predict(X_test_embed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}%\")\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=taxonomy_encoder.classes_)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode narratives\n",
    "X_tfidf = embedding.fit_transform(articles.values())\n",
    "\n",
    "# Encode taxonomy labels for classification\n",
    "taxonomy_encoder = LabelEncoder()\n",
    "y_taxonomy = taxonomy_encoder.fit_transform(annotations['taxonomy'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_taxonomy, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter narratives for URW and CC (excluding Other)\n",
    "narratives = annotations.loc[annotations['taxonomy'] != 'Other', 'narratives']\n",
    "narratives_encoder = MultiLabelBinarizer()\n",
    "y_narratives = narratives_encoder.fit_transform(narratives)\n",
    "# Use the same TF-IDF features (X_tfidf) for training\n",
    "X_train_narr, X_test_narr, y_train_narr, y_test_narr = train_test_split(\n",
    "    X_tfidf[annotations['taxonomy'] != 'Other'], y_narratives, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total F1-Score (Micro): 0.1658\n",
      "Total F1-Score (Macro): 0.0725\n",
      "Narrative Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.11      0.25      0.15         4\n",
      "           6       0.29      0.20      0.24        10\n",
      "           7       0.62      0.53      0.57        15\n",
      "           8       0.29      0.22      0.25         9\n",
      "           9       0.30      0.20      0.24        15\n",
      "          10       0.00      0.00      0.00         5\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.20      0.14      0.17       113\n",
      "   macro avg       0.08      0.07      0.07       113\n",
      "weighted avg       0.17      0.14      0.15       113\n",
      " samples avg       0.18      0.15      0.15       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hasan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "# Initialize and train Label Powerset classifier with XGBoost\n",
    "narrative_clf = LabelPowerset(model)\n",
    "narrative_clf.fit(X_train_narr, y_train_narr)\n",
    "\n",
    "# Predict narratives\n",
    "y_pred_narr = narrative_clf.predict(X_test_narr)\n",
    "\n",
    "# Evaluate narratives\n",
    "from sklearn.metrics import hamming_loss, jaccard_score\n",
    "f1_micro = f1_score(y_test_narr, y_pred_narr, average='micro')\n",
    "print(f\"Total F1-Score (Micro): {f1_micro:.4f}\")\n",
    "f1_macro = f1_score(y_test_narr, y_pred_narr, average='macro')\n",
    "print(f\"Total F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(\"Narrative Classification Report:\")\n",
    "print(classification_report(y_test_narr, y_pred_narr, target_names=narratives_encoder.classes, zero_division=0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter annotations to exclude 'Other'\n",
    "# sub_narratives_mask = annotations['taxonomy'] != 'Other'\n",
    "# sub_narratives = annotations.loc[sub_narratives_mask, 'sub_narratives']\n",
    "# X_sub_filtered = X_tfidf[sub_narratives_mask]\n",
    "\n",
    "# # Encode sub-narratives as multi-label\n",
    "# sub_narratives_encoder = MultiLabelBinarizer()\n",
    "# y_sub_narratives = sub_narratives_encoder.fit_transform(sub_narratives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X_sub_filtered, y_sub_narratives, test_size=0.2, random_state=42)\n",
    "# sub_narrative_clf = LabelPowerset(XGBClassifier(eval_metric='mlogloss', random_state=42))\n",
    "# sub_narrative_clf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_sub = sub_narrative_clf.predict(X_test_sub)\n",
    "# f1_micro_sub = f1_score(y_test_sub, y_pred_sub, average='micro')\n",
    "# print(f\"Micro F1-Score: {f1_micro_sub:.4f}\")\n",
    "# f1_macro_sub = f1_score(y_test_sub, y_pred_sub, average='macro')\n",
    "# print(f\"Macro F1-Score: {f1_macro_sub:.4f}\")\n",
    "# print(\"Sub-Narrative Classification Report:\")\n",
    "# print(classification_report(y_test_sub, y_pred_sub, target_names=sub_narratives_encoder.classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1-Score: 0.0846\n",
      "Macro F1-Score: 0.0494\n",
      "Sub-Narrative Classification Report:\n",
      "                                                                                                               precision    recall  f1-score   support\n",
      "\n",
      "                                        Amplifying Climate Fears: Amplifying existing fears of global warming       0.00      0.00      0.00         0\n",
      "                                                      Amplifying Climate Fears: Doomsday scenarios for humans       0.00      0.00      0.00         0\n",
      "                                                                              Amplifying Climate Fears: Other       0.00      0.00      0.00         0\n",
      "                                            Amplifying war-related fears: By continuing the war we risk WWIII       0.00      0.00      0.00         4\n",
      "                                            Amplifying war-related fears: NATO should/will directly intervene       0.00      0.00      0.00         0\n",
      "                                                                          Amplifying war-related fears: Other       0.00      0.00      0.00         2\n",
      "                                        Amplifying war-related fears: Russia will also attack other countries       0.00      0.00      0.00         1\n",
      "              Amplifying war-related fears: There is a real possibility that nuclear weapons will be employed       0.12      0.25      0.17         4\n",
      "                               Blaming the war on others rather than the invader: The West are the aggressors       0.17      0.12      0.14         8\n",
      "                                  Blaming the war on others rather than the invader: Ukraine is the aggressor       0.00      0.00      0.00         0\n",
      "                                                              Climate change is beneficial: CO2 is beneficial       0.00      0.00      0.00         0\n",
      "                                             Climate change is beneficial: Temperature increase is beneficial       0.00      0.00      0.00         0\n",
      "                                                                  Controversy about green technologies: Other       0.00      0.00      0.00         0\n",
      "                                             Controversy about green technologies: Renewable energy is costly       0.00      0.00      0.00         2\n",
      "                                          Controversy about green technologies: Renewable energy is dangerous       0.00      0.00      0.00         0\n",
      "                                         Controversy about green technologies: Renewable energy is unreliable       0.00      0.00      0.00         1\n",
      "                                           Criticism of climate movement: Ad hominem attacks on key activists       0.00      0.00      0.00         1\n",
      "                                                  Criticism of climate movement: Climate movement is alarmist       0.00      0.00      0.00         2\n",
      "                                                   Criticism of climate movement: Climate movement is corrupt       0.00      0.00      0.00         0\n",
      "                                                                         Criticism of climate movement: Other       0.00      0.00      0.00         1\n",
      "                                              Criticism of climate policies: Climate policies are ineffective       1.00      0.33      0.50         3\n",
      "                                          Criticism of climate policies: Climate policies are only for profit       0.00      0.00      0.00         3\n",
      "                          Criticism of climate policies: Climate policies have negative impact on the economy       0.00      0.00      0.00         6\n",
      "                                                                         Criticism of climate policies: Other       0.00      0.00      0.00         2\n",
      "                               Criticism of institutions and authorities: Criticism of international entities       0.00      0.00      0.00         2\n",
      "                                 Criticism of institutions and authorities: Criticism of national governments       0.17      0.12      0.14         8\n",
      "                  Criticism of institutions and authorities: Criticism of political organizations and figures       1.00      0.10      0.18        10\n",
      "                                               Criticism of institutions and authorities: Criticism of the EU       0.00      0.00      0.00         2\n",
      "                                                             Criticism of institutions and authorities: Other       0.00      0.00      0.00         0\n",
      "                           Discrediting Ukraine: Discrediting Ukrainian government and officials and policies       0.50      0.33      0.40         3\n",
      "                                                        Discrediting Ukraine: Discrediting Ukrainian military       0.00      0.00      0.00         1\n",
      "                                                          Discrediting Ukraine: Rewriting Ukraineâ€™s history       0.00      0.00      0.00         0\n",
      "                                                       Discrediting Ukraine: Situation in Ukraine is hopeless       0.00      0.00      0.00         1\n",
      "                                               Discrediting Ukraine: Ukraine is a hub for criminal activities       0.00      0.00      0.00         0\n",
      "                                                        Discrediting Ukraine: Ukraine is a puppet of the West       0.00      0.00      0.00         4\n",
      "                                                      Discrediting Ukraine: Ukraine is associated with nazism       1.00      0.25      0.40         4\n",
      "                                               Discrediting the West, Diplomacy: Diplomacy does/will not work       1.00      0.20      0.33         5\n",
      "                                                                      Discrediting the West, Diplomacy: Other       0.00      0.00      0.00         6\n",
      "                                                          Discrediting the West, Diplomacy: The EU is divided       0.00      0.00      0.00         1\n",
      "             Discrediting the West, Diplomacy: The West does not care about Ukraine, only about its interests       0.50      0.50      0.50         2\n",
      "                                                   Discrediting the West, Diplomacy: The West is overreacting       0.00      0.00      0.00         2\n",
      "                                                           Discrediting the West, Diplomacy: The West is weak       0.00      0.00      0.00         3\n",
      "                                                   Discrediting the West, Diplomacy: West is tired of Ukraine       0.00      0.00      0.00         4\n",
      "                                                    Distrust towards Media: Ukrainian media cannot be trusted       0.00      0.00      0.00         0\n",
      "                                         Distrust towards Media: Western media is an instrument of propaganda       0.00      0.00      0.00         5\n",
      "                               Downplaying climate change: CO2 concentrations are too small to have an impact       0.00      0.00      0.00         0\n",
      "                                                       Downplaying climate change: Climate cycles are natural       0.00      0.00      0.00         0\n",
      "                                    Downplaying climate change: Human activities do not impact climate change       0.00      0.00      0.00         0\n",
      "                                      Downplaying climate change: Humans and nature will adapt to the changes       0.00      0.00      0.00         1\n",
      "                                                               Downplaying climate change: Ice is not melting       0.00      0.00      0.00         0\n",
      "                                                                            Downplaying climate change: Other       0.00      0.00      0.00         1\n",
      "                                                        Downplaying climate change: Sea levels are not rising       0.00      0.00      0.00         0\n",
      "                            Downplaying climate change: Temperature increase does not have significant impact       0.00      0.00      0.00         0\n",
      "                                     Downplaying climate change: Weather suggests the trend is global cooling       0.00      0.00      0.00         0\n",
      "Green policies are geopolitical instruments: Climate-related international relations are abusive/exploitative       0.00      0.00      0.00         1\n",
      "                  Green policies are geopolitical instruments: Green activities are a form of neo-colonialism       0.00      0.00      0.00         0\n",
      "                                     Hidden plots by secret schemes of powerful groups: Blaming global elites       0.00      0.00      0.00         4\n",
      "                         Hidden plots by secret schemes of powerful groups: Climate agenda has hidden motives       0.33      0.25      0.29         4\n",
      "                                                     Hidden plots by secret schemes of powerful groups: Other       0.00      0.00      0.00         3\n",
      "                                                                    Negative Consequences for the West: Other       0.00      0.00      0.00         2\n",
      "                     Negative Consequences for the West: Sanctions imposed by Western countries will backfire       0.00      0.00      0.00         1\n",
      "         Negative Consequences for the West: The conflict will increase the Ukrainian refugee flows to Europe       0.00      0.00      0.00         0\n",
      "                                         Overpraising the West: The West belongs in the right side of history       0.00      0.00      0.00         2\n",
      "                                      Overpraising the West: The West has the strongest international support       0.00      0.00      0.00         1\n",
      "                                                                                      Praise of Russia: Other       0.00      0.00      0.00         0\n",
      "                                                 Praise of Russia: Praise of Russian President Vladimir Putin       0.00      0.00      0.00         1\n",
      "                                                           Praise of Russia: Praise of Russian military might       0.00      0.00      0.00         3\n",
      "                     Praise of Russia: Russia has international support from a number of countries and people       0.00      0.00      0.00         0\n",
      "                                              Praise of Russia: Russia is a guarantor of peace and prosperity       0.00      0.00      0.00         0\n",
      "                                               Praise of Russia: Russian invasion has strong national support       0.00      0.00      0.00         0\n",
      "                                 Questioning the measurements and science: Data shows no temperature increase       0.00      0.00      0.00         0\n",
      "       Questioning the measurements and science: Greenhouse effect/carbon dioxide do not drive climate change       0.00      0.00      0.00         1\n",
      "                   Questioning the measurements and science: Methodologies/metrics used are unreliable/faulty       0.00      0.00      0.00         3\n",
      "                                                              Questioning the measurements and science: Other       0.00      0.00      0.00         3\n",
      "                                 Questioning the measurements and science: Scientific community is unreliable       0.00      0.00      0.00         4\n",
      "                                                                                  Russia is the Victim: Other       0.00      0.00      0.00         1\n",
      "                                        Russia is the Victim: Russia actions in Ukraine are only self-defence       0.00      0.00      0.00         2\n",
      "                                                                Russia is the Victim: The West is russophobic       0.00      0.00      0.00         2\n",
      "                                                               Russia is the Victim: UA is anti-RU extremists       1.00      1.00      1.00         1\n",
      "                                                                              Speculating war outcomes: Other       0.00      0.00      0.00         4\n",
      "                                                         Speculating war outcomes: Russian army is collapsing       0.00      0.00      0.00         1\n",
      "                                                       Speculating war outcomes: Ukrainian army is collapsing       0.00      0.00      0.00         2\n",
      "\n",
      "                                                                                                    micro avg       0.10      0.07      0.08       151\n",
      "                                                                                                    macro avg       0.08      0.04      0.05       151\n",
      "                                                                                                 weighted avg       0.20      0.07      0.09       151\n",
      "                                                                                                  samples avg       0.10      0.06      0.07       151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hasan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sub_narratives = annotations.loc[annotations['taxonomy'] != 'Other', 'sub_narratives']\n",
    "\n",
    "# Step 2: Encode sub-narratives\n",
    "sub_narratives_encoder = MultiLabelBinarizer()\n",
    "y_sub_narratives = sub_narratives_encoder.fit_transform(sub_narratives)\n",
    "\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
    "    X_tfidf[annotations['taxonomy'] != 'Other'], y_sub_narratives, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Initialize and train Label Powerset classifier for sub-narratives\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sub_narrative_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "sub_narrative_clf = LabelPowerset(sub_narrative_model)\n",
    "sub_narrative_clf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# Step 5: Predict sub-narratives\n",
    "y_pred_sub = sub_narrative_clf.predict(X_test_sub)\n",
    "\n",
    "# Step 6: Evaluate predictions\n",
    "f1_micro_sub = f1_score(y_test_sub, y_pred_sub, average='micro')\n",
    "f1_macro_sub = f1_score(y_test_sub, y_pred_sub, average='macro')\n",
    "print(f\"Micro F1-Score: {f1_micro_sub:.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_macro_sub:.4f}\")\n",
    "\n",
    "print(\"Sub-Narrative Classification Report:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test_sub, \n",
    "        y_pred_sub, \n",
    "        target_names=sub_narratives_encoder.classes_, \n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
